{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_age_VGG16_Estimator_Training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LAZrCTjTD9eE",
        "WqVRivB1EBlA"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAZrCTjTD9eE",
        "colab_type": "text"
      },
      "source": [
        "## Data procesing\n",
        "wiki + IMDB\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eebdBs27JoM",
        "colab_type": "code",
        "outputId": "41298ca3-43fb-4f40-90de-0726a72357b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-14 20:55:39--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 811315200 (774M) [application/x-tar]\n",
            "Saving to: ‘wiki_crop.tar’\n",
            "\n",
            "wiki_crop.tar       100%[===================>] 773.73M  26.3MB/s    in 30s     \n",
            "\n",
            "2019-08-14 20:56:10 (25.6 MB/s) - ‘wiki_crop.tar’ saved [811315200/811315200]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXEVtabI7NSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf wiki_crop.tar\n",
        "!rm wiki_crop.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Z98xLiH-X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('./wiki_crop/wiki.mat')\n",
        "\n",
        "instances = mat['wiki'][0][0][0].shape[1]\n",
        "columns = ['dob', 'photo_taken', 'full_path', 'gender', \"name\", \"face_location\", \"face_score\", \"second_face_score\"]\n",
        "df_wiki = pd.DataFrame(index=range(0, instances), columns=columns)\n",
        "for i in mat:\n",
        "  if i == \"wiki\":\n",
        "    curr_array = mat[i][0][0]\n",
        "    for j in range(len(curr_array)):\n",
        "      df_wiki[columns[j]] = pd.DataFrame(curr_array[j][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iPJmyebUJrV",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "mat = scipy.io.loadmat('./imdb_crop/imdb.mat')\n",
        "\n",
        "instances_imdb = mat['imdb'][0][0][0].shape[1]\n",
        "# columns = ['dob', 'photo_taken', 'full_path', 'gender', \"name\", \"face_location\", \"face_score\", \"second_face_score\"]\n",
        "df_imdb = pd.DataFrame(index=range(0, instances_imdb), columns=columns)\n",
        "for i in mat:\n",
        "  if i == \"imdb\":\n",
        "    curr_array = mat[i][0][0]\n",
        "    print(len(curr_array))\n",
        "    for j in range(0, len(curr_array)-2): #imdb has 10 columns\n",
        "      df_imdb[columns[j]] = pd.DataFrame(curr_array[j][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM24X6_7NsXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " datetime.fromordinal(max(int(720044) - 366,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Xw3AS3MQc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cale_age(taken, dob):\n",
        "  \n",
        "  birth = datetime.fromordinal(max(int(dob) - 366,1))\n",
        "  \n",
        "  if birth.month < 7:\n",
        "    return taken - birth.year\n",
        "  else:\n",
        "    return taken - birth.year - 1\n",
        "\n",
        "df_wiki['age'] = [cale_age(df_wiki['photo_taken'][i], df_wiki['dob'][i]) for i in range(len(df_wiki['dob']))]\n",
        "#df_imdb['age'] = [cale_age(df_imdb['photo_taken'][i], df_imdb['dob'][i]) for i in range(len(df_imdb['dob']))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU47o430baM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean data\n",
        "#remove no face picture\n",
        "df_wiki = df_wiki[df_wiki['face_score'] != -np.inf]\n",
        "#remove more faces in one picuture\n",
        "df_wiki = df_wiki[df_wiki['second_face_score'].isna()]\n",
        "#threshold more than 3\n",
        "df_wiki = df_wiki[df_wiki['face_score'] >= 3]\n",
        "#remove no gender\n",
        "df_wiki = df_wiki[df_wiki['gender'].isna()==False]\n",
        "#reomve unuse columns\n",
        "df_wiki = df_wiki.drop(columns=['name', 'face_score', 'second_face_score', 'face_location'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdheuMKbiji",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "#clean data\n",
        "#remove no face picture\n",
        "df_imdb = df_imdb[df_imdb['face_score'] != -np.inf]\n",
        "#remove more faces in one picuture\n",
        "df_imdb = df_imdb[df_imdb['second_face_score'].isna()]\n",
        "#threshold more than 3\n",
        "df_imdb = df_imdb[df_imdb['face_score'] >= 3]\n",
        "#remove no gender\n",
        "df_imdb = df_imdb[df_imdb['gender'].isna()==False]\n",
        "#reomve unuse columns\n",
        "df_imdb = df_imdb.drop(columns=['name', 'face_score', 'second_face_score', 'face_location'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9_IYBzebCTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_wiki.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dT7gJmLXBZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_wiki = df_wiki[df_wiki['age']>0]\n",
        "df_wiki = df_wiki[df_wiki['age']<=100]\n",
        "\n",
        "# df_imdb = df_imdb[df_imdb['age']>0]\n",
        "# df_imdb = df_imdb[df_imdb['age']<=100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWkfvs8tVZBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_size = (224,224)\n",
        "#update to pixel value\n",
        "\n",
        "def getImagetoPixels(image_path, db='wiki'): #db = wiki or imdb\n",
        "  image = cv2.imread('{}_crop/{}'.format(db, image_path[0]), cv2.IMREAD_COLOR)\n",
        "  image = cv2.resize(image,target_size)\n",
        "#   print(db)\n",
        "  return image.reshape(1,-1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ72LgerZQiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image = cv2.imread('./wiki_crop/00/10049200_1891-09-16_1958.jpg', cv2.IMREAD_COLOR)\n",
        "# image = cv2.resize(image,target_size)\n",
        "# image = getImagetoPixels(['00/10049200_1891-09-16_1958.jpg'])\n",
        "# image.reshape(1,-1)[0]\n",
        "df_wiki['pixels'] = df_wiki['full_path'].apply(getImagetoPixels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkvJt6XWeNCk",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "df_imdb['pixels'] = df_imdb['full_path'].apply(getImagetoPixels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALM7jW49Ni_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df_wiki"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUoCKP8xpHOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df_wiki\n",
        "# del df_imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngs7SYNDaIG4",
        "colab_type": "code",
        "outputId": "e296ae62-db47-4f08-834f-36282e873af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape #(115549, 6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22138, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03AUkWlVh6DR",
        "colab_type": "code",
        "outputId": "1eeaac64-ccf4-4b5e-efee-98efc63169bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from PIL import Image\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Layer, Input, Dropout, Conv2D, Activation, add, BatchNormalization, UpSampling2D, ZeroPadding2D, Conv2DTranspose, Flatten, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend import mean\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import plot_model, to_categorical\n",
        "from keras.engine.topology import Network #for untrainable discrimator model but weight still is updated\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDdjFmHudRIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_classes = to_categorical(df['age'].values, 101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVQOIQXITlrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_features = []\n",
        "for i in range(0, df.shape[0]):\n",
        "  image_features.append(df['pixels'].values[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3i2NJ7Rin_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tempfile import mkdtemp\n",
        "import os.path as path\n",
        "\n",
        "filename_array = path.join(mkdtemp(), 'image_features_array.dat')\n",
        "fp_image_features_array = np.memmap(filename_array, dtype='float32', mode='w+',\\\n",
        "                                    shape=(len(image_features), 224*224*3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RkjwJKWnISc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(0, len(image_features)):\n",
        "fp_image_features_array[:] = np.array(image_features[:])\n",
        "#   print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WTnGXG9eZI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del image_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcT5MxfnsKku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp_image_features_array.flush()\n",
        "# fp_image_features_array.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuAvJ_D6PVu5",
        "colab_type": "code",
        "outputId": "b2e42184-288b-4aee-9808-a034068a7c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fp_image_features_array.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22138, 150528)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZNlrmEDecdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tempfile import mkdtemp\n",
        "import os.path as path\n",
        "filename = path.join(mkdtemp(), 'imageFeaturefile.dat')\n",
        "fp = np.memmap(filename, dtype='float32', mode='w+', shape=(fp_image_features_array.shape[0],224,224,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPknIjIgc-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp[:] = fp_image_features_array.reshape(fp_image_features_array.shape[0], 224, 224, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G7Mq6ZtEvAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp[:] = fp/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfpKWC58h68o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_mp = path.join(mkdtemp(), 'train_x.dat')\n",
        "train_x = np.memmap(train_x_mp, dtype='float32', mode='w+', shape=(int(fp.shape[0] * 0.7),224,224,3))\n",
        "\n",
        "train_y_mp = path.join(mkdtemp(), 'train_y.dat')\n",
        "train_y = np.memmap(train_y_mp, dtype='float32', mode='w+', shape=(int(fp.shape[0] * 0.7),101))\n",
        "\n",
        "# test_x_mp = path.join(mkdtemp(), 'test_x.dat')\n",
        "# test_x = np.memmap(test_x_mp, dtype='float32', mode='w+', shape=(int(fp.shape[0] * 0.3),224,224,3))\n",
        "\n",
        "# test_y_mp = path.join(mkdtemp(), 'test_y.dat')\n",
        "# test_y = np.memmap(test_y_mp, dtype='float32', mode='w+', shape=(int(fp.shape[0] * 0.3),2))\n",
        "\n",
        "test_x_mp = path.join(mkdtemp(), 'test_x.dat')\n",
        "test_x = np.memmap(test_x_mp, dtype='float32', mode='w+', shape=(6642,224,224,3))\n",
        "\n",
        "test_y_mp = path.join(mkdtemp(), 'test_y.dat')\n",
        "test_y = np.memmap(test_y_mp, dtype='float32', mode='w+', shape=(6642,101))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsyeN4ndg7Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x[:], test_x[:], train_y[:], test_y[:] = train_test_split(fp, target_classes, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DImONOs36YMo",
        "colab_type": "code",
        "outputId": "e3000a3b-4500-48df-b2f3-15ecdc811f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6642, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqVRivB1EBlA",
        "colab_type": "text"
      },
      "source": [
        "## Involving VGG FACE\n",
        "https://github.com/rcmalli/keras-vggface.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmwxOzNECXs",
        "colab_type": "code",
        "outputId": "70728638-070d-4bce-f1a5-a7efa570d625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-90xiuvzg\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-90xiuvzg\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=8d32bb627ef02e1952912ca07de4fafb2a4a08a01fa59f774c74c577dac9e131\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fph56x3h/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKLt2s-DmmNm",
        "colab_type": "code",
        "outputId": "0fdcfd1a-c89d-45ea-cc39-d8b6391531e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "from keras_vggface.vggface import VGGFace\n",
        "vgg_model = VGGFace(include_top=False, model='vgg16', weights='vggface', input_shape=(224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0814 21:12:45.092542 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0814 21:12:45.310530 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0814 21:12:45.365767 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0814 21:12:45.462373 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58916864/58909280 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0814 21:12:47.400665 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0814 21:12:47.402165 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82J-hWMjxXHF",
        "colab_type": "code",
        "outputId": "50a866e9-4ddb-40de-e884-ec49c659a0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "vgg_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWVnLgbgPSpC",
        "colab_type": "code",
        "outputId": "ca340daa-7369-4cba-c7e1-57eaa4be967a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#add top layers\n",
        "last_layer  = vgg_model.get_layer('pool5').output\n",
        "for layer in vgg_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Conv2D(4096, (7, 7), activation='relu')(last_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv2D(4096, (1, 1), activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv2D(101, (1,1),name=\"prediction\")(x) #for age estimator\n",
        "\n",
        "x = Flatten(name='flatten')(x)\n",
        "output = Activation('softmax')(x)\n",
        "\n",
        "facegender_vgg_model = Model(vgg_model.input, output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0814 21:12:51.078122 140266772465536 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7EIJfmruIzi",
        "colab_type": "code",
        "outputId": "0738e7fe-4bf5-4350-8441-12c390570fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "facegender_vgg_model.compile(loss='categorical_crossentropy', \\\n",
        "                          optimizer=Adam(), \\\n",
        "                          metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0814 21:13:25.842913 140266772465536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcJk7NHI3nQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in facegender_vgg_model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkmifGWQ1de2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='age_model.h5', \\\n",
        "                               monitor= 'val_loss', \\\n",
        "                               verbose=1, \\\n",
        "                               save_best_only=True,\\\n",
        "                               mode = 'auto'\n",
        "                               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vyzT5wXtdYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVYecQ51SIDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_track = TensorBoard(log_dir='./face_age_estimator_logs', histogram_freq=0, \\\n",
        "                            batch_size=256, \\\n",
        "                            write_graph=True,\\\n",
        "                            write_grads=False, \\\n",
        "                            write_images=False, \\\n",
        "                            embeddings_freq=0, \\\n",
        "                            embeddings_layer_names=None, \\\n",
        "                            embeddings_metadata=None,\\\n",
        "                            embeddings_data=None,\\\n",
        "                            update_freq='epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPMxCXr15M4",
        "colab_type": "code",
        "outputId": "98ca752f-10f8-4681-b7fc-ef089cef66ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 250\n",
        "batch_size = 256\n",
        "scores = []\n",
        "for i in range(epochs):\n",
        "\n",
        "  ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
        "  score = faceage_vgg_model.fit(train_x[ix_train], train_y[ix_train]\n",
        " , epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])\n",
        "  \n",
        "  print(i)\n",
        "  \n",
        "  histories.append(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0814 21:13:41.430041 140266772465536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 93s 365ms/step - loss: 5.0217 - acc: 0.0195 - val_loss: 4.4094 - val_acc: 0.0372\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.40944, saving model to age_model.h5\n",
            "0\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 4.3478 - acc: 0.0430 - val_loss: 4.1948 - val_acc: 0.0367\n",
            "\n",
            "Epoch 00001: val_loss improved from 4.40944 to 4.19482, saving model to age_model.h5\n",
            "1\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 4.2216 - acc: 0.0352 - val_loss: 4.0776 - val_acc: 0.0370\n",
            "\n",
            "Epoch 00001: val_loss improved from 4.19482 to 4.07765, saving model to age_model.h5\n",
            "2\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 3.9617 - acc: 0.0234 - val_loss: 3.9899 - val_acc: 0.0382\n",
            "\n",
            "Epoch 00001: val_loss improved from 4.07765 to 3.98995, saving model to age_model.h5\n",
            "3\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 4.0273 - acc: 0.0312 - val_loss: 3.9667 - val_acc: 0.0381\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.98995 to 3.96673, saving model to age_model.h5\n",
            "4\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.9435 - acc: 0.0352 - val_loss: 3.9214 - val_acc: 0.0403\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.96673 to 3.92141, saving model to age_model.h5\n",
            "5\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.8839 - acc: 0.0664 - val_loss: 3.9163 - val_acc: 0.0438\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.92141 to 3.91626, saving model to age_model.h5\n",
            "6\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.7647 - acc: 0.0625 - val_loss: 3.8715 - val_acc: 0.0391\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.91626 to 3.87150, saving model to age_model.h5\n",
            "7\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.8081 - acc: 0.0586 - val_loss: 3.8578 - val_acc: 0.0468\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.87150 to 3.85776, saving model to age_model.h5\n",
            "8\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.9366 - acc: 0.0586 - val_loss: 3.8096 - val_acc: 0.0391\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.85776 to 3.80955, saving model to age_model.h5\n",
            "9\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.8092 - acc: 0.0547 - val_loss: 3.8271 - val_acc: 0.0437\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.80955\n",
            "10\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.8199 - acc: 0.0547 - val_loss: 3.7937 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.80955 to 3.79374, saving model to age_model.h5\n",
            "11\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.7789 - acc: 0.0742 - val_loss: 3.7573 - val_acc: 0.0456\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.79374 to 3.75731, saving model to age_model.h5\n",
            "12\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.8126 - acc: 0.0195 - val_loss: 3.7487 - val_acc: 0.0390\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.75731 to 3.74873, saving model to age_model.h5\n",
            "13\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.7741 - acc: 0.0625 - val_loss: 3.7341 - val_acc: 0.0479\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.74873 to 3.73405, saving model to age_model.h5\n",
            "14\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 86s 335ms/step - loss: 3.8775 - acc: 0.0312 - val_loss: 3.7306 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.73405 to 3.73063, saving model to age_model.h5\n",
            "15\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 84s 330ms/step - loss: 3.7826 - acc: 0.0508 - val_loss: 3.7445 - val_acc: 0.0489\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.73063\n",
            "16\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 322ms/step - loss: 3.8275 - acc: 0.0312 - val_loss: 3.6940 - val_acc: 0.0471\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.73063 to 3.69402, saving model to age_model.h5\n",
            "17\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 3.8143 - acc: 0.0430 - val_loss: 3.7026 - val_acc: 0.0468\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.69402\n",
            "18\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 86s 336ms/step - loss: 3.7178 - acc: 0.0391 - val_loss: 3.6741 - val_acc: 0.0468\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.69402 to 3.67409, saving model to age_model.h5\n",
            "19\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 85s 332ms/step - loss: 3.7266 - acc: 0.0508 - val_loss: 3.6802 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.67409\n",
            "20\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.6410 - acc: 0.0703 - val_loss: 3.6790 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.67409\n",
            "21\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.7437 - acc: 0.0625 - val_loss: 3.7038 - val_acc: 0.0462\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.67409\n",
            "22\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.7670 - acc: 0.0312 - val_loss: 3.6846 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.67409\n",
            "23\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6599 - acc: 0.0625 - val_loss: 3.6751 - val_acc: 0.0500\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.67409\n",
            "24\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.7357 - acc: 0.0625 - val_loss: 3.6525 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.67409 to 3.65251, saving model to age_model.h5\n",
            "25\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5910 - acc: 0.0938 - val_loss: 3.6436 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.65251 to 3.64358, saving model to age_model.h5\n",
            "26\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.6410 - acc: 0.0625 - val_loss: 3.6540 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64358\n",
            "27\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.7320 - acc: 0.0547 - val_loss: 3.6420 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.64358 to 3.64202, saving model to age_model.h5\n",
            "28\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6759 - acc: 0.0547 - val_loss: 3.6463 - val_acc: 0.0489\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64202\n",
            "29\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.8227 - acc: 0.0469 - val_loss: 3.6435 - val_acc: 0.0471\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64202\n",
            "30\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5081 - acc: 0.0820 - val_loss: 3.6471 - val_acc: 0.0447\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64202\n",
            "31\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6807 - acc: 0.0508 - val_loss: 3.6624 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64202\n",
            "32\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6167 - acc: 0.0586 - val_loss: 3.6466 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.64202\n",
            "33\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5967 - acc: 0.0391 - val_loss: 3.6093 - val_acc: 0.0563\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.64202 to 3.60926, saving model to age_model.h5\n",
            "34\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.6081 - acc: 0.0547 - val_loss: 3.6185 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.60926\n",
            "35\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6313 - acc: 0.0391 - val_loss: 3.5930 - val_acc: 0.0572\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.60926 to 3.59303, saving model to age_model.h5\n",
            "36\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.6911 - acc: 0.0742 - val_loss: 3.6135 - val_acc: 0.0548\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.59303\n",
            "37\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5910 - acc: 0.0977 - val_loss: 3.6195 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.59303\n",
            "38\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6125 - acc: 0.0547 - val_loss: 3.6031 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.59303\n",
            "39\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5865 - acc: 0.0703 - val_loss: 3.6057 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.59303\n",
            "40\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6357 - acc: 0.0586 - val_loss: 3.5935 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.59303\n",
            "41\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6213 - acc: 0.0586 - val_loss: 3.5552 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.59303 to 3.55522, saving model to age_model.h5\n",
            "42\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.5338 - acc: 0.0742 - val_loss: 3.5945 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "43\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6218 - acc: 0.0703 - val_loss: 3.5901 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "44\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.7115 - acc: 0.0508 - val_loss: 3.5889 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "45\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.6289 - acc: 0.0508 - val_loss: 3.6059 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "46\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6002 - acc: 0.0781 - val_loss: 3.5878 - val_acc: 0.0574\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "47\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4633 - acc: 0.0664 - val_loss: 3.5751 - val_acc: 0.0516\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "48\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.7043 - acc: 0.0469 - val_loss: 3.5691 - val_acc: 0.0527\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "49\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6378 - acc: 0.0742 - val_loss: 3.5639 - val_acc: 0.0596\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "50\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4991 - acc: 0.0977 - val_loss: 3.5953 - val_acc: 0.0560\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "51\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.7594 - acc: 0.0508 - val_loss: 3.6400 - val_acc: 0.0431\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "52\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6117 - acc: 0.0391 - val_loss: 3.5739 - val_acc: 0.0519\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "53\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6133 - acc: 0.0898 - val_loss: 3.5603 - val_acc: 0.0574\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55522\n",
            "54\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5341 - acc: 0.0859 - val_loss: 3.5507 - val_acc: 0.0559\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.55522 to 3.55070, saving model to age_model.h5\n",
            "55\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.4924 - acc: 0.0781 - val_loss: 3.5595 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55070\n",
            "56\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4512 - acc: 0.0703 - val_loss: 3.5679 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.55070\n",
            "57\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5963 - acc: 0.0547 - val_loss: 3.5429 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.55070 to 3.54293, saving model to age_model.h5\n",
            "58\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5562 - acc: 0.0586 - val_loss: 3.5611 - val_acc: 0.0534\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "59\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5568 - acc: 0.0625 - val_loss: 3.5762 - val_acc: 0.0568\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "60\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6306 - acc: 0.0742 - val_loss: 3.5472 - val_acc: 0.0498\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "61\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.8139 - acc: 0.0547 - val_loss: 3.5681 - val_acc: 0.0568\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "62\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6272 - acc: 0.0469 - val_loss: 3.5643 - val_acc: 0.0619\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "63\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6734 - acc: 0.0547 - val_loss: 3.6128 - val_acc: 0.0467\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "64\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.6233 - acc: 0.0742 - val_loss: 3.5714 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "65\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5624 - acc: 0.0430 - val_loss: 3.5778 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "66\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5287 - acc: 0.0742 - val_loss: 3.5815 - val_acc: 0.0542\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "67\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5166 - acc: 0.0859 - val_loss: 3.5721 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "68\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5629 - acc: 0.0898 - val_loss: 3.5871 - val_acc: 0.0479\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "69\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5646 - acc: 0.0664 - val_loss: 3.5627 - val_acc: 0.0572\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "70\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.7023 - acc: 0.0547 - val_loss: 3.5573 - val_acc: 0.0575\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "71\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5652 - acc: 0.0625 - val_loss: 3.5757 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "72\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6065 - acc: 0.0898 - val_loss: 3.5865 - val_acc: 0.0492\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54293\n",
            "73\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5198 - acc: 0.0625 - val_loss: 3.5415 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.54293 to 3.54150, saving model to age_model.h5\n",
            "74\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.5513 - acc: 0.0391 - val_loss: 3.5527 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.54150\n",
            "75\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4595 - acc: 0.0898 - val_loss: 3.5391 - val_acc: 0.0501\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.54150 to 3.53912, saving model to age_model.h5\n",
            "76\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.4883 - acc: 0.0742 - val_loss: 3.5555 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "77\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5442 - acc: 0.0469 - val_loss: 3.5605 - val_acc: 0.0530\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "78\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5892 - acc: 0.0508 - val_loss: 3.5512 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "79\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5422 - acc: 0.0547 - val_loss: 3.5420 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "80\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4339 - acc: 0.0703 - val_loss: 3.5682 - val_acc: 0.0544\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "81\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6080 - acc: 0.0820 - val_loss: 3.5523 - val_acc: 0.0565\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "82\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5125 - acc: 0.0703 - val_loss: 3.5401 - val_acc: 0.0577\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53912\n",
            "83\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4569 - acc: 0.0859 - val_loss: 3.5332 - val_acc: 0.0601\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.53912 to 3.53319, saving model to age_model.h5\n",
            "84\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.5947 - acc: 0.0703 - val_loss: 3.5431 - val_acc: 0.0592\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53319\n",
            "85\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6378 - acc: 0.0742 - val_loss: 3.5388 - val_acc: 0.0586\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53319\n",
            "86\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4488 - acc: 0.0938 - val_loss: 3.5520 - val_acc: 0.0497\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.53319\n",
            "87\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6668 - acc: 0.0586 - val_loss: 3.5290 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.53319 to 3.52901, saving model to age_model.h5\n",
            "88\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4631 - acc: 0.0625 - val_loss: 3.5381 - val_acc: 0.0524\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.52901\n",
            "89\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5814 - acc: 0.0625 - val_loss: 3.5777 - val_acc: 0.0494\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.52901\n",
            "90\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5618 - acc: 0.0820 - val_loss: 3.5227 - val_acc: 0.0602\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.52901 to 3.52268, saving model to age_model.h5\n",
            "91\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.5111 - acc: 0.0820 - val_loss: 3.5181 - val_acc: 0.0563\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.52268 to 3.51811, saving model to age_model.h5\n",
            "92\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4610 - acc: 0.0898 - val_loss: 3.5685 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51811\n",
            "93\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5329 - acc: 0.0664 - val_loss: 3.5265 - val_acc: 0.0623\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51811\n",
            "94\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5098 - acc: 0.1172 - val_loss: 3.5148 - val_acc: 0.0562\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.51811 to 3.51480, saving model to age_model.h5\n",
            "95\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5057 - acc: 0.1016 - val_loss: 3.5407 - val_acc: 0.0494\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51480\n",
            "96\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4088 - acc: 0.0938 - val_loss: 3.5800 - val_acc: 0.0464\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51480\n",
            "97\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.3685 - acc: 0.1016 - val_loss: 3.6045 - val_acc: 0.0417\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51480\n",
            "98\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4035 - acc: 0.0859 - val_loss: 3.5318 - val_acc: 0.0583\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51480\n",
            "99\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5665 - acc: 0.0859 - val_loss: 3.5527 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.51480\n",
            "100\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4617 - acc: 0.0898 - val_loss: 3.4999 - val_acc: 0.0581\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.51480 to 3.49987, saving model to age_model.h5\n",
            "101\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3959 - acc: 0.0742 - val_loss: 3.5405 - val_acc: 0.0545\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "102\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4518 - acc: 0.1172 - val_loss: 3.5216 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "103\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5645 - acc: 0.0938 - val_loss: 3.5461 - val_acc: 0.0584\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "104\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4156 - acc: 0.0664 - val_loss: 3.5276 - val_acc: 0.0534\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "105\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6191 - acc: 0.0625 - val_loss: 3.5617 - val_acc: 0.0513\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "106\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5719 - acc: 0.0781 - val_loss: 3.5489 - val_acc: 0.0458\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "107\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4992 - acc: 0.0586 - val_loss: 3.5518 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "108\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5293 - acc: 0.0781 - val_loss: 3.5290 - val_acc: 0.0599\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "109\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.4389 - acc: 0.0938 - val_loss: 3.5624 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "110\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4874 - acc: 0.0703 - val_loss: 3.5275 - val_acc: 0.0513\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "111\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3950 - acc: 0.1055 - val_loss: 3.5124 - val_acc: 0.0587\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "112\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4089 - acc: 0.1133 - val_loss: 3.5964 - val_acc: 0.0524\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "113\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4673 - acc: 0.0820 - val_loss: 3.5519 - val_acc: 0.0581\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "114\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4526 - acc: 0.0664 - val_loss: 3.5421 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "115\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5458 - acc: 0.0664 - val_loss: 3.5218 - val_acc: 0.0530\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "116\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5077 - acc: 0.0977 - val_loss: 3.5242 - val_acc: 0.0580\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "117\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4023 - acc: 0.1016 - val_loss: 3.5248 - val_acc: 0.0577\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "118\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3781 - acc: 0.1055 - val_loss: 3.5712 - val_acc: 0.0441\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "119\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3139 - acc: 0.0977 - val_loss: 3.5259 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "120\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3463 - acc: 0.1055 - val_loss: 3.5036 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "121\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3828 - acc: 0.1094 - val_loss: 3.5265 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "122\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4118 - acc: 0.1211 - val_loss: 3.5217 - val_acc: 0.0559\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "123\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4830 - acc: 0.0938 - val_loss: 3.6175 - val_acc: 0.0456\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "124\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5152 - acc: 0.0938 - val_loss: 3.5499 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "125\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4417 - acc: 0.0938 - val_loss: 3.5237 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49987\n",
            "126\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.5436 - acc: 0.0742 - val_loss: 3.4939 - val_acc: 0.0578\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.49987 to 3.49390, saving model to age_model.h5\n",
            "127\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3462 - acc: 0.1289 - val_loss: 3.4971 - val_acc: 0.0604\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "128\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3233 - acc: 0.1133 - val_loss: 3.5302 - val_acc: 0.0565\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "129\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4702 - acc: 0.0938 - val_loss: 3.5284 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "130\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3064 - acc: 0.1016 - val_loss: 3.5212 - val_acc: 0.0556\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "131\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4125 - acc: 0.1094 - val_loss: 3.5276 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "132\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4819 - acc: 0.0742 - val_loss: 3.5710 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "133\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3839 - acc: 0.1250 - val_loss: 3.5245 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "134\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3784 - acc: 0.1016 - val_loss: 3.5303 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "135\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6006 - acc: 0.0898 - val_loss: 3.5699 - val_acc: 0.0486\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "136\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4647 - acc: 0.0820 - val_loss: 3.5303 - val_acc: 0.0577\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "137\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3937 - acc: 0.0938 - val_loss: 3.5697 - val_acc: 0.0565\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "138\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4216 - acc: 0.1094 - val_loss: 3.5207 - val_acc: 0.0515\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "139\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3619 - acc: 0.1016 - val_loss: 3.5351 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "140\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2981 - acc: 0.1367 - val_loss: 3.5130 - val_acc: 0.0545\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "141\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4444 - acc: 0.1445 - val_loss: 3.5608 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "142\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4069 - acc: 0.0820 - val_loss: 3.5356 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "143\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3949 - acc: 0.1094 - val_loss: 3.5660 - val_acc: 0.0530\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "144\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5303 - acc: 0.0898 - val_loss: 3.5196 - val_acc: 0.0512\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "145\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.6405 - acc: 0.0703 - val_loss: 3.6020 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "146\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3592 - acc: 0.0820 - val_loss: 3.5047 - val_acc: 0.0590\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "147\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3939 - acc: 0.1211 - val_loss: 3.5282 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "148\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4933 - acc: 0.0938 - val_loss: 3.5324 - val_acc: 0.0556\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "149\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4034 - acc: 0.1094 - val_loss: 3.5582 - val_acc: 0.0516\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "150\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2877 - acc: 0.1250 - val_loss: 3.5291 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "151\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.5153 - acc: 0.0977 - val_loss: 3.5364 - val_acc: 0.0595\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "152\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.4381 - acc: 0.1055 - val_loss: 3.5156 - val_acc: 0.0593\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "153\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4066 - acc: 0.1016 - val_loss: 3.5220 - val_acc: 0.0486\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "154\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4896 - acc: 0.0898 - val_loss: 3.5445 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "155\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.3690 - acc: 0.0938 - val_loss: 3.5421 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "156\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.2640 - acc: 0.1328 - val_loss: 3.5285 - val_acc: 0.0545\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "157\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3660 - acc: 0.0938 - val_loss: 3.5296 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "158\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3711 - acc: 0.1055 - val_loss: 3.5264 - val_acc: 0.0548\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "159\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3076 - acc: 0.0898 - val_loss: 3.5301 - val_acc: 0.0568\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "160\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3911 - acc: 0.1133 - val_loss: 3.5098 - val_acc: 0.0557\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "161\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3380 - acc: 0.1328 - val_loss: 3.5112 - val_acc: 0.0580\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "162\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3172 - acc: 0.1211 - val_loss: 3.5065 - val_acc: 0.0584\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "163\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3949 - acc: 0.0898 - val_loss: 3.5658 - val_acc: 0.0550\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "164\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.5078 - acc: 0.0977 - val_loss: 3.5323 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "165\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3812 - acc: 0.1094 - val_loss: 3.5135 - val_acc: 0.0580\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "166\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.4822 - acc: 0.0820 - val_loss: 3.5438 - val_acc: 0.0548\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "167\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3729 - acc: 0.0938 - val_loss: 3.5200 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "168\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3480 - acc: 0.1289 - val_loss: 3.5227 - val_acc: 0.0556\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "169\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.4205 - acc: 0.0859 - val_loss: 3.5060 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "170\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3822 - acc: 0.1055 - val_loss: 3.5287 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "171\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3146 - acc: 0.1133 - val_loss: 3.5098 - val_acc: 0.0557\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "172\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3558 - acc: 0.1172 - val_loss: 3.5096 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "173\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3062 - acc: 0.1211 - val_loss: 3.5234 - val_acc: 0.0497\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "174\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.4226 - acc: 0.0859 - val_loss: 3.5192 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "175\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2404 - acc: 0.1172 - val_loss: 3.5031 - val_acc: 0.0556\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "176\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2093 - acc: 0.1367 - val_loss: 3.5146 - val_acc: 0.0580\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "177\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3060 - acc: 0.1172 - val_loss: 3.5293 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "178\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3977 - acc: 0.1016 - val_loss: 3.5292 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "179\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3459 - acc: 0.1445 - val_loss: 3.5191 - val_acc: 0.0560\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "180\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2337 - acc: 0.1289 - val_loss: 3.5307 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "181\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2930 - acc: 0.1055 - val_loss: 3.5015 - val_acc: 0.0587\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.49390\n",
            "182\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2632 - acc: 0.1250 - val_loss: 3.4885 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.49390 to 3.48848, saving model to age_model.h5\n",
            "183\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.4109 - acc: 0.1211 - val_loss: 3.5250 - val_acc: 0.0613\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "184\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2376 - acc: 0.1445 - val_loss: 3.5160 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "185\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2925 - acc: 0.1133 - val_loss: 3.4991 - val_acc: 0.0545\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "186\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2533 - acc: 0.1133 - val_loss: 3.5252 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "187\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3181 - acc: 0.1367 - val_loss: 3.5185 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "188\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.4334 - acc: 0.1289 - val_loss: 3.5069 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "189\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2697 - acc: 0.1172 - val_loss: 3.5157 - val_acc: 0.0589\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "190\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2969 - acc: 0.1406 - val_loss: 3.5065 - val_acc: 0.0602\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "191\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2598 - acc: 0.1172 - val_loss: 3.5124 - val_acc: 0.0613\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "192\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3247 - acc: 0.1055 - val_loss: 3.4974 - val_acc: 0.0605\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "193\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.0338 - acc: 0.1602 - val_loss: 3.5201 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "194\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.4188 - acc: 0.1094 - val_loss: 3.5146 - val_acc: 0.0562\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "195\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.2906 - acc: 0.1406 - val_loss: 3.5156 - val_acc: 0.0575\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "196\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 316ms/step - loss: 3.3576 - acc: 0.1211 - val_loss: 3.5058 - val_acc: 0.0568\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "197\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.2522 - acc: 0.1133 - val_loss: 3.4912 - val_acc: 0.0593\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "198\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.1840 - acc: 0.1484 - val_loss: 3.5117 - val_acc: 0.0574\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "199\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3374 - acc: 0.1133 - val_loss: 3.5393 - val_acc: 0.0548\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "200\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3070 - acc: 0.1602 - val_loss: 3.5109 - val_acc: 0.0589\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "201\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3098 - acc: 0.1406 - val_loss: 3.5058 - val_acc: 0.0593\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "202\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3906 - acc: 0.0742 - val_loss: 3.5175 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "203\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.1966 - acc: 0.1094 - val_loss: 3.5166 - val_acc: 0.0563\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "204\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3434 - acc: 0.1133 - val_loss: 3.4969 - val_acc: 0.0574\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "205\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2915 - acc: 0.1523 - val_loss: 3.5331 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "206\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4020 - acc: 0.0977 - val_loss: 3.5024 - val_acc: 0.0569\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48848\n",
            "207\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.2484 - acc: 0.1172 - val_loss: 3.4823 - val_acc: 0.0581\n",
            "\n",
            "Epoch 00001: val_loss improved from 3.48848 to 3.48228, saving model to age_model.h5\n",
            "208\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3634 - acc: 0.1367 - val_loss: 3.4949 - val_acc: 0.0550\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "209\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2651 - acc: 0.1172 - val_loss: 3.5169 - val_acc: 0.0544\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "210\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.2902 - acc: 0.1445 - val_loss: 3.4904 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "211\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.3225 - acc: 0.1250 - val_loss: 3.5038 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "212\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.1732 - acc: 0.1445 - val_loss: 3.5277 - val_acc: 0.0527\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "213\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.1987 - acc: 0.1250 - val_loss: 3.5063 - val_acc: 0.0540\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "214\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.1675 - acc: 0.1562 - val_loss: 3.4929 - val_acc: 0.0578\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "215\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3238 - acc: 0.1367 - val_loss: 3.5187 - val_acc: 0.0553\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "216\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.2452 - acc: 0.1406 - val_loss: 3.5372 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "217\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3377 - acc: 0.1562 - val_loss: 3.5522 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "218\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.4136 - acc: 0.1328 - val_loss: 3.5771 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "219\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.2299 - acc: 0.1406 - val_loss: 3.5406 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "220\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.2580 - acc: 0.1406 - val_loss: 3.5132 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "221\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.2065 - acc: 0.1250 - val_loss: 3.5249 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "222\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.1652 - acc: 0.1484 - val_loss: 3.5144 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "223\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.3493 - acc: 0.1406 - val_loss: 3.5079 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "224\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 318ms/step - loss: 3.2183 - acc: 0.1367 - val_loss: 3.5083 - val_acc: 0.0504\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "225\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.4771 - acc: 0.0781 - val_loss: 3.5258 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "226\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.3501 - acc: 0.1055 - val_loss: 3.5215 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "227\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 318ms/step - loss: 3.2863 - acc: 0.1133 - val_loss: 3.4921 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "228\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2446 - acc: 0.1094 - val_loss: 3.5016 - val_acc: 0.0557\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "229\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2702 - acc: 0.1328 - val_loss: 3.5148 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "230\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 318ms/step - loss: 3.4259 - acc: 0.0898 - val_loss: 3.5217 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "231\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.2206 - acc: 0.1172 - val_loss: 3.5585 - val_acc: 0.0477\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "232\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2019 - acc: 0.1523 - val_loss: 3.5044 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "233\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 318ms/step - loss: 3.1040 - acc: 0.1562 - val_loss: 3.5314 - val_acc: 0.0556\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "234\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 319ms/step - loss: 3.2608 - acc: 0.1328 - val_loss: 3.5648 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "235\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3835 - acc: 0.1016 - val_loss: 3.5338 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "236\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 81s 317ms/step - loss: 3.3998 - acc: 0.0742 - val_loss: 3.5143 - val_acc: 0.0578\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "237\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 320ms/step - loss: 3.3370 - acc: 0.1211 - val_loss: 3.5099 - val_acc: 0.0620\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "238\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 3.3580 - acc: 0.1445 - val_loss: 3.4879 - val_acc: 0.0632\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "239\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 2.9884 - acc: 0.2109 - val_loss: 3.4885 - val_acc: 0.0635\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "240\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 3.3302 - acc: 0.1562 - val_loss: 3.5023 - val_acc: 0.0554\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "241\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 326ms/step - loss: 3.1618 - acc: 0.1445 - val_loss: 3.5266 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "242\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 322ms/step - loss: 3.1025 - acc: 0.1602 - val_loss: 3.5091 - val_acc: 0.0495\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "243\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 322ms/step - loss: 3.1419 - acc: 0.1602 - val_loss: 3.5196 - val_acc: 0.0482\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "244\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 321ms/step - loss: 3.3386 - acc: 0.1484 - val_loss: 3.5369 - val_acc: 0.0524\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "245\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 82s 322ms/step - loss: 3.2252 - acc: 0.1680 - val_loss: 3.5518 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "246\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 323ms/step - loss: 3.3176 - acc: 0.1602 - val_loss: 3.5048 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "247\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 325ms/step - loss: 3.1988 - acc: 0.1641 - val_loss: 3.4857 - val_acc: 0.0581\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "248\n",
            "Train on 256 samples, validate on 6642 samples\n",
            "Epoch 1/1\n",
            "256/256 [==============================] - 83s 325ms/step - loss: 3.2936 - acc: 0.1367 - val_loss: 3.5106 - val_acc: 0.0537\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 3.48228\n",
            "249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m67Y9ELKJIf",
        "colab_type": "code",
        "outputId": "fdca15ca-156a-4fc9-f58a-7ed54dc2c9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import time\n",
        "\n",
        "time.ctime()\n",
        "xian\n",
        "#10:30 ~ 15:14"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thu Aug 15 03:01:59 2019'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}